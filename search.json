[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#github-repository",
    "href": "posts/Environmental Machine Learning Project/index.html#github-repository",
    "title": "Environmental Data Project",
    "section": "GitHub Repository",
    "text": "GitHub Repository\nHere’s a link to the GitHub repo"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#dataset",
    "href": "posts/Environmental Machine Learning Project/index.html#dataset",
    "title": "Environmental Data Project",
    "section": "Dataset",
    "text": "Dataset\nBefore choosing a specific topic, I did data exploration for various datasets to see which would be the most interesting. I looked at: - US Census https://github.com/zykls/folktablesLinks - Covid19 - https://www.kaggle.com/imdevskp/covid-19-analysis-visualization-comparisons/dataLink - Uber: https://www.kaggle.com/datasets/yasserh/uber-fares-dataset - NYC: https://data.cityofnewyork.us/browse?category=Transportation"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#environmental-data-analysis",
    "href": "posts/Environmental Machine Learning Project/index.html#environmental-data-analysis",
    "title": "Environmental Data Project",
    "section": "Environmental Data Analysis",
    "text": "Environmental Data Analysis\n\n“How have land use, air quality, disasters, and climate variables changed over time? What factors are related to this?”\nCreated an account with Public EM-DAT to access a global database on natural and technological disasters\n\nConfigured parameters to obtain custom dataset\n\n\n\nimport pandas as pd\n\ndf = pd.read_excel(\"emdat.xlsx\", engine=\"openpyxl\")  \n\nprint(df.head())\n\n          DisNo. Historic Classification Key Disaster Group Disaster Subgroup  \\\n0  1999-9388-DJI       No    nat-cli-dro-dro        Natural    Climatological   \n1  1999-9388-SDN       No    nat-cli-dro-dro        Natural    Climatological   \n2  1999-9388-SOM       No    nat-cli-dro-dro        Natural    Climatological   \n3  2000-0001-AGO       No    tec-tra-roa-roa  Technological         Transport   \n4  2000-0002-AGO       No    nat-hyd-flo-riv        Natural      Hydrological   \n\n  Disaster Type Disaster Subtype External IDs Event Name  ISO  ...  \\\n0       Drought          Drought          NaN        NaN  DJI  ...   \n1       Drought          Drought          NaN        NaN  SDN  ...   \n2       Drought          Drought          NaN        NaN  SOM  ...   \n3          Road             Road          NaN        NaN  AGO  ...   \n4         Flood   Riverine flood          NaN        NaN  AGO  ...   \n\n  Reconstruction Costs ('000 US$) Reconstruction Costs, Adjusted ('000 US$)  \\\n0                             NaN                                       NaN   \n1                             NaN                                       NaN   \n2                             NaN                                       NaN   \n3                             NaN                                       NaN   \n4                             NaN                                       NaN   \n\n  Insured Damage ('000 US$) Insured Damage, Adjusted ('000 US$)  \\\n0                       NaN                                 NaN   \n1                       NaN                                 NaN   \n2                       NaN                                 NaN   \n3                       NaN                                 NaN   \n4                       NaN                                 NaN   \n\n  Total Damage ('000 US$) Total Damage, Adjusted ('000 US$)        CPI  \\\n0                     NaN                               NaN  58.111474   \n1                     NaN                               NaN  56.514291   \n2                     NaN                               NaN  56.514291   \n3                     NaN                               NaN  56.514291   \n4                 10000.0                           17695.0  56.514291   \n\n                                         Admin Units  Entry Date  Last Update  \n0  [{\"adm1_code\":1093,\"adm1_name\":\"Ali Sabieh\"},{...  2006-03-01   2023-09-25  \n1  [{\"adm1_code\":2757,\"adm1_name\":\"Northern Darfu...  2006-03-08   2023-09-25  \n2  [{\"adm1_code\":2691,\"adm1_name\":\"Bay\"},{\"adm1_c...  2006-03-08   2023-09-25  \n3                                                NaN  2004-10-27   2023-09-25  \n4  [{\"adm2_code\":4214,\"adm2_name\":\"Baia Farta\"},{...  2005-02-03   2023-09-25  \n\n[5 rows x 46 columns]\n\n\nLet’s inspect the data\n\ndf.info()\ndf.describe()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 16209 entries, 0 to 16208\nData columns (total 46 columns):\n #   Column                                     Non-Null Count  Dtype  \n---  ------                                     --------------  -----  \n 0   DisNo.                                     16209 non-null  object \n 1   Historic                                   16209 non-null  object \n 2   Classification Key                         16209 non-null  object \n 3   Disaster Group                             16209 non-null  object \n 4   Disaster Subgroup                          16209 non-null  object \n 5   Disaster Type                              16209 non-null  object \n 6   Disaster Subtype                           16209 non-null  object \n 7   External IDs                               2709 non-null   object \n 8   Event Name                                 5105 non-null   object \n 9   ISO                                        16209 non-null  object \n 10  Country                                    16209 non-null  object \n 11  Subregion                                  16209 non-null  object \n 12  Region                                     16209 non-null  object \n 13  Location                                   15499 non-null  object \n 14  Origin                                     4076 non-null   object \n 15  Associated Types                           3438 non-null   object \n 16  OFDA/BHA Response                          16209 non-null  object \n 17  Appeal                                     16209 non-null  object \n 18  Declaration                                16209 non-null  object \n 19  AID Contribution ('000 US$)                489 non-null    float64\n 20  Magnitude                                  3311 non-null   float64\n 21  Magnitude Scale                            10137 non-null  object \n 22  Latitude                                   1816 non-null   float64\n 23  Longitude                                  1816 non-null   float64\n 24  River Basin                                1233 non-null   object \n 25  Start Year                                 16209 non-null  int64  \n 26  Start Month                                16140 non-null  float64\n 27  Start Day                                  14638 non-null  float64\n 28  End Year                                   16209 non-null  int64  \n 29  End Month                                  16046 non-null  float64\n 30  End Day                                    14710 non-null  float64\n 31  Total Deaths                               13039 non-null  float64\n 32  No. Injured                                6019 non-null   float64\n 33  No. Affected                               7503 non-null   float64\n 34  No. Homeless                               1333 non-null   float64\n 35  Total Affected                             12087 non-null  float64\n 36  Reconstruction Costs ('000 US$)            33 non-null     float64\n 37  Reconstruction Costs, Adjusted ('000 US$)  33 non-null     float64\n 38  Insured Damage ('000 US$)                  713 non-null    float64\n 39  Insured Damage, Adjusted ('000 US$)        694 non-null    float64\n 40  Total Damage ('000 US$)                    3237 non-null   float64\n 41  Total Damage, Adjusted ('000 US$)          3110 non-null   float64\n 42  CPI                                        15527 non-null  float64\n 43  Admin Units                                8416 non-null   object \n 44  Entry Date                                 16209 non-null  object \n 45  Last Update                                16209 non-null  object \ndtypes: float64(20), int64(2), object(24)\nmemory usage: 5.7+ MB\n\n\n\n\n\n\n\n\n\nAID Contribution ('000 US$)\nMagnitude\nLatitude\nLongitude\nStart Year\nStart Month\nStart Day\nEnd Year\nEnd Month\nEnd Day\n...\nNo. Affected\nNo. Homeless\nTotal Affected\nReconstruction Costs ('000 US$)\nReconstruction Costs, Adjusted ('000 US$)\nInsured Damage ('000 US$)\nInsured Damage, Adjusted ('000 US$)\nTotal Damage ('000 US$)\nTotal Damage, Adjusted ('000 US$)\nCPI\n\n\n\n\ncount\n4.890000e+02\n3.311000e+03\n1816.000000\n1816.000000\n16209.000000\n16140.000000\n14638.000000\n16209.000000\n16046.000000\n14710.000000\n...\n7.503000e+03\n1.333000e+03\n1.208700e+04\n3.300000e+01\n3.300000e+01\n7.130000e+02\n6.940000e+02\n3.237000e+03\n3.110000e+03\n15527.000000\n\n\nmean\n2.855916e+04\n6.122545e+04\n16.415862\n42.477620\n2011.109816\n6.463755\n15.352849\n2011.141156\n6.592858\n15.814276\n...\n6.280205e+05\n3.162704e+04\n3.939913e+05\n5.687264e+06\n6.357118e+06\n1.347736e+06\n1.699765e+06\n1.178820e+06\n1.478426e+06\n72.858610\n\n\nstd\n2.118956e+05\n7.486415e+05\n21.786044\n75.523526\n7.422845\n3.413559\n8.973253\n7.425922\n3.391621\n8.891107\n...\n6.649927e+06\n2.143536e+05\n5.249462e+06\n1.745232e+07\n1.760343e+07\n4.644761e+06\n5.954430e+06\n6.317104e+06\n8.316465e+06\n11.582942\n\n\nmin\n3.000000e+00\n-5.700000e+01\n-72.640000\n-172.095000\n2000.000000\n1.000000\n1.000000\n2000.000000\n1.000000\n1.000000\n...\n1.000000e+00\n3.000000e+00\n1.000000e+00\n8.400000e+01\n1.310000e+02\n3.400000e+01\n4.800000e+01\n2.000000e+00\n3.000000e+00\n56.514291\n\n\n25%\n1.660000e+02\n2.350000e+01\n1.061500\n1.676500\n2005.000000\n4.000000\n7.000000\n2005.000000\n4.000000\n8.000000\n...\n6.000000e+02\n3.400000e+02\n4.200000e+01\n1.000000e+05\n1.000000e+05\n7.500000e+04\n9.917050e+04\n1.600000e+04\n2.132325e+04\n61.989586\n\n\n50%\n7.650000e+02\n2.000000e+02\n18.642500\n55.574500\n2010.000000\n7.000000\n15.000000\n2010.000000\n7.000000\n16.000000\n...\n6.500000e+03\n1.966000e+03\n1.000000e+03\n5.650000e+05\n7.023360e+05\n2.500000e+05\n3.491245e+05\n1.000000e+05\n1.420280e+05\n71.563596\n\n\n75%\n4.984000e+03\n2.173700e+04\n34.786750\n103.235250\n2018.000000\n9.000000\n23.000000\n2018.000000\n9.000000\n24.000000\n...\n6.003500e+04\n7.000000e+03\n1.757050e+04\n3.344000e+06\n4.245383e+06\n8.000000e+05\n1.117445e+06\n5.500000e+05\n7.172402e+05\n80.445779\n\n\nmax\n3.518530e+06\n4.000000e+07\n67.930000\n179.650000\n2025.000000\n12.000000\n31.000000\n2025.000000\n12.000000\n31.000000\n...\n3.300000e+08\n5.000000e+06\n3.300000e+08\n1.000000e+08\n1.000000e+08\n6.000000e+07\n9.361435e+07\n2.100000e+08\n2.844652e+08\n100.000000\n\n\n\n\n8 rows × 22 columns"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#data-cleaning",
    "href": "posts/Environmental Machine Learning Project/index.html#data-cleaning",
    "title": "Environmental Data Project",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nGet rid of columns where the data is irrelevant or there’s not enough of it for it to be interesting.\n\ndf.isna().sum().sort_values(ascending=False)\n\nReconstruction Costs, Adjusted ('000 US$)    16176\nReconstruction Costs ('000 US$)              16176\nAID Contribution ('000 US$)                  15720\nInsured Damage, Adjusted ('000 US$)          15515\nInsured Damage ('000 US$)                    15496\nRiver Basin                                  14976\nNo. Homeless                                 14876\nLongitude                                    14393\nLatitude                                     14393\nExternal IDs                                 13500\nTotal Damage, Adjusted ('000 US$)            13099\nTotal Damage ('000 US$)                      12972\nMagnitude                                    12898\nAssociated Types                             12771\nOrigin                                       12133\nEvent Name                                   11104\nNo. Injured                                  10190\nNo. Affected                                  8706\nAdmin Units                                   7793\nMagnitude Scale                               6072\nTotal Affected                                4122\nTotal Deaths                                  3170\nStart Day                                     1571\nEnd Day                                       1499\nLocation                                       710\nCPI                                            682\nEnd Month                                      163\nStart Month                                     69\nEntry Date                                       0\nDisNo.                                           0\nEnd Year                                         0\nStart Year                                       0\nHistoric                                         0\nDeclaration                                      0\nAppeal                                           0\nOFDA/BHA Response                                0\nRegion                                           0\nSubregion                                        0\nCountry                                          0\nISO                                              0\nDisaster Subtype                                 0\nDisaster Type                                    0\nDisaster Subgroup                                0\nDisaster Group                                   0\nClassification Key                               0\nLast Update                                      0\ndtype: int64\n\n\n\ndf = df.drop(columns=[ 'DisNo.', 'External IDs','Event Name', 'Origin','Associated Types','Appeal','Declaration','OFDA/BHA Response','AID Contribution (\\'000 US$)',  'Reconstruction Costs (\\'000 US$)','Reconstruction Costs, Adjusted (\\'000 US$)','Insured Damage (\\'000 US$)','Insured Damage, Adjusted (\\'000 US$)','River Basin','Admin Units','Entry Date','Last Update'   ], errors='ignore')\ndf\n\n\n\n\n\n\n\n\nHistoric\nClassification Key\nDisaster Group\nDisaster Subgroup\nDisaster Type\nDisaster Subtype\nISO\nCountry\nSubregion\nRegion\n...\nEnd Month\nEnd Day\nTotal Deaths\nNo. Injured\nNo. Affected\nNo. Homeless\nTotal Affected\nTotal Damage ('000 US$)\nTotal Damage, Adjusted ('000 US$)\nCPI\n\n\n\n\n0\nNo\nnat-cli-dro-dro\nNatural\nClimatological\nDrought\nDrought\nDJI\nDjibouti\nSub-Saharan Africa\nAfrica\n...\nNaN\nNaN\nNaN\nNaN\n100000.0\nNaN\n100000.0\nNaN\nNaN\n58.111474\n\n\n1\nNo\nnat-cli-dro-dro\nNatural\nClimatological\nDrought\nDrought\nSDN\nSudan\nNorthern Africa\nAfrica\n...\nNaN\nNaN\nNaN\nNaN\n2000000.0\nNaN\n2000000.0\nNaN\nNaN\n56.514291\n\n\n2\nNo\nnat-cli-dro-dro\nNatural\nClimatological\nDrought\nDrought\nSOM\nSomalia\nSub-Saharan Africa\nAfrica\n...\nNaN\nNaN\n21.0\nNaN\n1200000.0\nNaN\n1200000.0\nNaN\nNaN\n56.514291\n\n\n3\nNo\ntec-tra-roa-roa\nTechnological\nTransport\nRoad\nRoad\nAGO\nAngola\nSub-Saharan Africa\nAfrica\n...\n1.0\n26.0\n14.0\n11.0\nNaN\nNaN\n11.0\nNaN\nNaN\n56.514291\n\n\n4\nNo\nnat-hyd-flo-riv\nNatural\nHydrological\nFlood\nRiverine flood\nAGO\nAngola\nSub-Saharan Africa\nAfrica\n...\n1.0\n15.0\n31.0\nNaN\n70000.0\nNaN\n70000.0\n10000.0\n17695.0\n56.514291\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n16204\nNo\ntec-tra-roa-roa\nTechnological\nTransport\nRoad\nRoad\nBRA\nBrazil\nLatin America and the Caribbean\nAmericas\n...\n4.0\n8.0\n10.0\n18.0\nNaN\nNaN\n18.0\nNaN\nNaN\nNaN\n\n\n16205\nNo\ntec-mis-fir-fir\nTechnological\nMiscellaneous accident\nFire (Miscellaneous)\nFire (Miscellaneous)\nCHN\nChina\nEastern Asia\nAsia\n...\n4.0\n8.0\n20.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n16206\nNo\nnat-met-sto-san\nNatural\nMeteorological\nStorm\nSand/Dust storm\nIRQ\nIraq\nWestern Asia\nAsia\n...\n4.0\n14.0\nNaN\n2751.0\nNaN\nNaN\n2751.0\nNaN\nNaN\nNaN\n\n\n16207\nNo\nnat-met-sto-sto\nNatural\nMeteorological\nStorm\nStorm (General)\nSPI\nCanary Islands\nNorthern Africa\nAfrica\n...\n4.0\n13.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n16208\nNo\nnat-cli-dro-dro\nNatural\nClimatological\nDrought\nDrought\nSOM\nSomalia\nSub-Saharan Africa\nAfrica\n...\nNaN\nNaN\nNaN\nNaN\n4400000.0\nNaN\n4400000.0\nNaN\nNaN\nNaN\n\n\n\n\n16209 rows × 29 columns\n\n\n\nLet’s also get rid of data points if it’s missing important variables we care about.\n\ndf = df.dropna(subset=['Country', 'Disaster Type', 'Start Year'])\ndf\n\n\n\n\n\n\n\n\nHistoric\nClassification Key\nDisaster Group\nDisaster Subgroup\nDisaster Type\nDisaster Subtype\nISO\nCountry\nSubregion\nRegion\n...\nEnd Month\nEnd Day\nTotal Deaths\nNo. Injured\nNo. Affected\nNo. Homeless\nTotal Affected\nTotal Damage ('000 US$)\nTotal Damage, Adjusted ('000 US$)\nCPI\n\n\n\n\n0\nNo\nnat-cli-dro-dro\nNatural\nClimatological\nDrought\nDrought\nDJI\nDjibouti\nSub-Saharan Africa\nAfrica\n...\nNaN\nNaN\nNaN\nNaN\n100000.0\nNaN\n100000.0\nNaN\nNaN\n58.111474\n\n\n1\nNo\nnat-cli-dro-dro\nNatural\nClimatological\nDrought\nDrought\nSDN\nSudan\nNorthern Africa\nAfrica\n...\nNaN\nNaN\nNaN\nNaN\n2000000.0\nNaN\n2000000.0\nNaN\nNaN\n56.514291\n\n\n2\nNo\nnat-cli-dro-dro\nNatural\nClimatological\nDrought\nDrought\nSOM\nSomalia\nSub-Saharan Africa\nAfrica\n...\nNaN\nNaN\n21.0\nNaN\n1200000.0\nNaN\n1200000.0\nNaN\nNaN\n56.514291\n\n\n3\nNo\ntec-tra-roa-roa\nTechnological\nTransport\nRoad\nRoad\nAGO\nAngola\nSub-Saharan Africa\nAfrica\n...\n1.0\n26.0\n14.0\n11.0\nNaN\nNaN\n11.0\nNaN\nNaN\n56.514291\n\n\n4\nNo\nnat-hyd-flo-riv\nNatural\nHydrological\nFlood\nRiverine flood\nAGO\nAngola\nSub-Saharan Africa\nAfrica\n...\n1.0\n15.0\n31.0\nNaN\n70000.0\nNaN\n70000.0\n10000.0\n17695.0\n56.514291\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n16204\nNo\ntec-tra-roa-roa\nTechnological\nTransport\nRoad\nRoad\nBRA\nBrazil\nLatin America and the Caribbean\nAmericas\n...\n4.0\n8.0\n10.0\n18.0\nNaN\nNaN\n18.0\nNaN\nNaN\nNaN\n\n\n16205\nNo\ntec-mis-fir-fir\nTechnological\nMiscellaneous accident\nFire (Miscellaneous)\nFire (Miscellaneous)\nCHN\nChina\nEastern Asia\nAsia\n...\n4.0\n8.0\n20.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n16206\nNo\nnat-met-sto-san\nNatural\nMeteorological\nStorm\nSand/Dust storm\nIRQ\nIraq\nWestern Asia\nAsia\n...\n4.0\n14.0\nNaN\n2751.0\nNaN\nNaN\n2751.0\nNaN\nNaN\nNaN\n\n\n16207\nNo\nnat-met-sto-sto\nNatural\nMeteorological\nStorm\nStorm (General)\nSPI\nCanary Islands\nNorthern Africa\nAfrica\n...\n4.0\n13.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n16208\nNo\nnat-cli-dro-dro\nNatural\nClimatological\nDrought\nDrought\nSOM\nSomalia\nSub-Saharan Africa\nAfrica\n...\nNaN\nNaN\nNaN\nNaN\n4400000.0\nNaN\n4400000.0\nNaN\nNaN\nNaN\n\n\n\n\n16209 rows × 29 columns\n\n\n\nGet rid of duplicates\n\ndf = df.drop_duplicates()\ndf\n\n\n\n\n\n\n\n\nHistoric\nClassification Key\nDisaster Group\nDisaster Subgroup\nDisaster Type\nDisaster Subtype\nISO\nCountry\nSubregion\nRegion\n...\nEnd Month\nEnd Day\nTotal Deaths\nNo. Injured\nNo. Affected\nNo. Homeless\nTotal Affected\nTotal Damage ('000 US$)\nTotal Damage, Adjusted ('000 US$)\nCPI\n\n\n\n\n0\nNo\nnat-cli-dro-dro\nNatural\nClimatological\nDrought\nDrought\nDJI\nDjibouti\nSub-Saharan Africa\nAfrica\n...\nNaN\nNaN\nNaN\nNaN\n100000.0\nNaN\n100000.0\nNaN\nNaN\n58.111474\n\n\n1\nNo\nnat-cli-dro-dro\nNatural\nClimatological\nDrought\nDrought\nSDN\nSudan\nNorthern Africa\nAfrica\n...\nNaN\nNaN\nNaN\nNaN\n2000000.0\nNaN\n2000000.0\nNaN\nNaN\n56.514291\n\n\n2\nNo\nnat-cli-dro-dro\nNatural\nClimatological\nDrought\nDrought\nSOM\nSomalia\nSub-Saharan Africa\nAfrica\n...\nNaN\nNaN\n21.0\nNaN\n1200000.0\nNaN\n1200000.0\nNaN\nNaN\n56.514291\n\n\n3\nNo\ntec-tra-roa-roa\nTechnological\nTransport\nRoad\nRoad\nAGO\nAngola\nSub-Saharan Africa\nAfrica\n...\n1.0\n26.0\n14.0\n11.0\nNaN\nNaN\n11.0\nNaN\nNaN\n56.514291\n\n\n4\nNo\nnat-hyd-flo-riv\nNatural\nHydrological\nFlood\nRiverine flood\nAGO\nAngola\nSub-Saharan Africa\nAfrica\n...\n1.0\n15.0\n31.0\nNaN\n70000.0\nNaN\n70000.0\n10000.0\n17695.0\n56.514291\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n16204\nNo\ntec-tra-roa-roa\nTechnological\nTransport\nRoad\nRoad\nBRA\nBrazil\nLatin America and the Caribbean\nAmericas\n...\n4.0\n8.0\n10.0\n18.0\nNaN\nNaN\n18.0\nNaN\nNaN\nNaN\n\n\n16205\nNo\ntec-mis-fir-fir\nTechnological\nMiscellaneous accident\nFire (Miscellaneous)\nFire (Miscellaneous)\nCHN\nChina\nEastern Asia\nAsia\n...\n4.0\n8.0\n20.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n16206\nNo\nnat-met-sto-san\nNatural\nMeteorological\nStorm\nSand/Dust storm\nIRQ\nIraq\nWestern Asia\nAsia\n...\n4.0\n14.0\nNaN\n2751.0\nNaN\nNaN\n2751.0\nNaN\nNaN\nNaN\n\n\n16207\nNo\nnat-met-sto-sto\nNatural\nMeteorological\nStorm\nStorm (General)\nSPI\nCanary Islands\nNorthern Africa\nAfrica\n...\n4.0\n13.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n16208\nNo\nnat-cli-dro-dro\nNatural\nClimatological\nDrought\nDrought\nSOM\nSomalia\nSub-Saharan Africa\nAfrica\n...\nNaN\nNaN\nNaN\nNaN\n4400000.0\nNaN\n4400000.0\nNaN\nNaN\nNaN\n\n\n\n\n16209 rows × 29 columns"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#interesting-variables",
    "href": "posts/Environmental Machine Learning Project/index.html#interesting-variables",
    "title": "Environmental Data Project",
    "section": "Interesting Variables:",
    "text": "Interesting Variables:\n\nDisaster Type\n\nLocation (country, region, longitude, latitude)\nTotal Deaths, No. Affected, and No. Injured\nTime (start day, start month, etc.)\nCost (Reconstruction Costs and Total Damage)"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#research-questions",
    "href": "posts/Environmental Machine Learning Project/index.html#research-questions",
    "title": "Environmental Data Project",
    "section": "Research Questions:",
    "text": "Research Questions:\n\n“Which countries have experienced the highest number of natural disasters in the past 25 years?”\n\n\nWe’ll need to investigate variables on countries, when it occured, and type of disaster\n\n\n“Are certain types of disasters becoming more common over time?”\n\n\nWe’ll need to investigate variables on time, when it occured, and type of disaster\nLet’s consider limitations with this dataset since it starts in 2000\n\n\n“Can we predict the average number of deaths or affected people for an event based on disaster type and context?”\n\n\nWe’ll need to investigate variables on Total Deaths, No. Affected, and No. Injured and type of disaster\n\n\n“Can we experiment with data forecasting and predict the number of disasters a country might experience based on its historical trends and geography?”\n\n\nWe’ll need to investigate variables on type of disaster, when it occured, and location\nWe’ll need to incorporate another dataset on geography\n\n\n“Can we classify the severity of a disaster based on its type, location, and year?”\n\n\nWe’ll need to investigate variables on type, location, time, and severity"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#tools-needed",
    "href": "posts/Environmental Machine Learning Project/index.html#tools-needed",
    "title": "Environmental Data Project",
    "section": "Tools Needed",
    "text": "Tools Needed\n\nFor visualizations, matplotlib, geopanda, seaborn and plotly\nFor machine learning, specifically forecasting, we can try Scikit-learn for regression or classification models or LSTM\nFor classification, we can use it to identify patterns or relationships among disasters"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#lets-get-started-on-first-research-question",
    "href": "posts/Environmental Machine Learning Project/index.html#lets-get-started-on-first-research-question",
    "title": "Environmental Data Project",
    "section": "Let’s get started on first research question",
    "text": "Let’s get started on first research question\n\n“Which countries have experienced the highest number of natural disasters?”\n\n\nWe’ll need to investigate variables on countries, when it occured, and type of disaster\n\n\ndisaster_count_by_country_df = df.groupby(['Country']).agg(\n    disaster_count=('Disaster Type', 'count')\n).reset_index().sort_values(by='disaster_count', ascending=False)\n\n\ndisaster_count_by_country_df\n\n\n\n\n\n\n\n\nCountry\ndisaster_count\n\n\n\n\n39\nChina\n1356\n\n\n89\nIndia\n820\n\n\n212\nUnited States of America\n724\n\n\n90\nIndonesia\n565\n\n\n152\nPhilippines\n474\n\n\n...\n...\n...\n\n\n5\nAnguilla\n1\n\n\n218\nWallis and Futuna Islands\n1\n\n\n164\nSaint Helena\n1\n\n\n135\nNetherlands Antilles\n1\n\n\n49\nCuraçao\n1\n\n\n\n\n222 rows × 2 columns\n\n\n\n\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default=\"iframe\"\n\nfig = px.scatter(\n    disaster_count_by_country_df.query('disaster_count&gt;=300'),\n    x=\"Country\",\n    y=\"disaster_count\",\n    size=\"disaster_count\",\n    color=\"Country\",\n    hover_name=\"Country\",\n    log_y=True, \n    size_max=100,\n    title=\"Number of Disaster Types by Country\"\n)\n\nfig.show()"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#analysis-of-first-research-question",
    "href": "posts/Environmental Machine Learning Project/index.html#analysis-of-first-research-question",
    "title": "Environmental Data Project",
    "section": "Analysis of first research question",
    "text": "Analysis of first research question\nFrom this visualization, we can see that India, China, and the USA have experienced the highest number of natural disasters. This is likely due to their large size, which means that there is more surface area taken into account. Surprising countries are the ones that are smaller but still have faced many natural disasters, such as the Philippines and Nigeria."
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#lets-get-started-on-the-second-research-question",
    "href": "posts/Environmental Machine Learning Project/index.html#lets-get-started-on-the-second-research-question",
    "title": "Environmental Data Project",
    "section": "Let’s get started on the second research question",
    "text": "Let’s get started on the second research question\n\n“Are certain types of disasters becoming more common over time?”\n\n\nWe’ll need to investigate variables on time, when it occured, and type of disaster\nLet’s consider limitations with this dataset since it starts in 2000\n\n\ndisaster_counts = df.groupby(['Start Year', 'Disaster Type']).size().reset_index(name='Count')\n\ndisaster_counts\n\n\n\n\n\n\n\n\nStart Year\nDisaster Type\nCount\n\n\n\n\n0\n2000\nAir\n31\n\n\n1\n2000\nChemical spill\n3\n\n\n2\n2000\nCollapse (Industrial)\n3\n\n\n3\n2000\nCollapse (Miscellaneous)\n11\n\n\n4\n2000\nDrought\n27\n\n\n...\n...\n...\n...\n\n\n609\n2025\nRail\n1\n\n\n610\n2025\nRoad\n19\n\n\n611\n2025\nStorm\n26\n\n\n612\n2025\nWater\n4\n\n\n613\n2025\nWildfire\n8\n\n\n\n\n614 rows × 3 columns\n\n\n\n\nfig = px.line(\n    disaster_counts,\n    x='Start Year',\n    y='Count',\n    color='Disaster Type',  \n    title='Disaster Types Over Time',\n    labels={'Year': 'Year', 'Count': 'Number of Disasters'},\n)\n\nfig.show()"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#analysis-of-second-research-question",
    "href": "posts/Environmental Machine Learning Project/index.html#analysis-of-second-research-question",
    "title": "Environmental Data Project",
    "section": "Analysis of second research question",
    "text": "Analysis of second research question\nFrom this visualization, we can see that it is difficult to answer if there are certain types of disasters becoming more common over time. This is because of our limited data set that starts in the year 2000. To answer, this question, we would need to find data that dates back far enough to see a difference in the frequency of certain disaster types."
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#visualization-to-explore-relationship-between-total-deaths-and-occurence-count-for-each-disaster-subtype",
    "href": "posts/Environmental Machine Learning Project/index.html#visualization-to-explore-relationship-between-total-deaths-and-occurence-count-for-each-disaster-subtype",
    "title": "Environmental Data Project",
    "section": "Visualization to explore relationship between total deaths and occurence count for each disaster subtype",
    "text": "Visualization to explore relationship between total deaths and occurence count for each disaster subtype\n\nscatter_data = df.groupby('Disaster Subtype').agg(\n    total_deaths=('Total Deaths', 'sum'),\n    occurrence_count=('Disaster Subtype', 'count')\n).reset_index()\n\nscatter_data\n\n\n\n\n\n\n\n\nDisaster Subtype\ntotal_deaths\noccurrence_count\n\n\n\n\n0\nAir\n17267.0\n439\n\n\n1\nAnimal incident\n12.0\n1\n\n\n2\nAsh fall\n663.0\n102\n\n\n3\nAvalanche (dry)\n16.0\n1\n\n\n4\nAvalanche (wet)\n1889.0\n54\n\n\n...\n...\n...\n...\n\n\n58\nViral disease\n47825.0\n350\n\n\n59\nVolcanic activity (General)\n516.0\n11\n\n\n60\nWater\n51946.0\n1149\n\n\n61\nWildfire (General)\n702.0\n85\n\n\n62\nWorms infestation\n0.0\n2\n\n\n\n\n63 rows × 3 columns\n\n\n\n\nfig = px.scatter(\n    scatter_data,\n    x='Disaster Subtype',\n    y='total_deaths',\n    size='occurrence_count',    \n    color='Disaster Subtype',     \n    title='Disaster Subtypes: Total Deaths vs. Occurrence Count',\n    labels={\n        'disaster_subtype': 'Disaster Subtype',\n        'total_deaths': 'Total Deaths'\n    },\n)\n\n\n\nfig.show()"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#analysis-of-scatterplot-visualization",
    "href": "posts/Environmental Machine Learning Project/index.html#analysis-of-scatterplot-visualization",
    "title": "Environmental Data Project",
    "section": "Analysis of scatterplot visualization",
    "text": "Analysis of scatterplot visualization\nWe can see that Ground Movement is an outlier and has the highest number of deaths at around 550k. In terms of disaster subtypes with the largest occurence count, we can notice Road, Riverine Flood, Flood, Water, and Tropical Cyclone. We can see that most of these are natural with the exception of Road."
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#map-visualization-on-devastating-disasters-around-the-world",
    "href": "posts/Environmental Machine Learning Project/index.html#map-visualization-on-devastating-disasters-around-the-world",
    "title": "Environmental Data Project",
    "section": "Map Visualization on Devastating Disasters Around the World",
    "text": "Map Visualization on Devastating Disasters Around the World\n\nmap_df = df[(df['Latitude'].notna()) & (df['Longitude'].notna())]\n\nmap_df['Total Deaths'] = map_df['Total Deaths'].fillna(0)\n\nmap_df = map_df[(map_df['Total Deaths'] &gt; 0)]\n\nmap_df\n\n/var/folders/h6/1nj6sx2s1nxdyfr36bhcxvlc0000gn/T/ipykernel_2016/904054904.py:3: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n\n\n\n\n\n\n\nHistoric\nClassification Key\nDisaster Group\nDisaster Subgroup\nDisaster Type\nDisaster Subtype\nISO\nCountry\nSubregion\nRegion\n...\nEnd Month\nEnd Day\nTotal Deaths\nNo. Injured\nNo. Affected\nNo. Homeless\nTotal Affected\nTotal Damage ('000 US$)\nTotal Damage, Adjusted ('000 US$)\nCPI\n\n\n\n\n33\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nCHN\nChina\nEastern Asia\nAsia\n...\n1.0\n14.0\n7.0\n2528.0\n1760000.0\n92479.0\n1855007.0\n73500.0\n130056.0\n56.514291\n\n\n36\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nCHN\nChina\nEastern Asia\nAsia\n...\n1.0\n26.0\n1.0\n2.0\n10300.0\nNaN\n10302.0\n483.0\n855.0\n56.514291\n\n\n50\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nIRN\nIran (Islamic Republic of)\nSouthern Asia\nAsia\n...\n2.0\n2.0\n1.0\n15.0\n1500.0\n500.0\n2015.0\nNaN\nNaN\n56.514291\n\n\n75\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nCOL\nColombia\nLatin America and the Caribbean\nAmericas\n...\n11.0\n8.0\n2.0\nNaN\n430.0\nNaN\n430.0\nNaN\nNaN\n56.514291\n\n\n208\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nIDN\nIndonesia\nSouth-eastern Asia\nAsia\n...\n5.0\n4.0\n45.0\n270.0\nNaN\n52500.0\n52770.0\n30000.0\n53084.0\n56.514291\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n16091\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nCHN\nChina\nEastern Asia\nAsia\n...\n1.0\n7.0\n126.0\n188.0\n46500.0\nNaN\n46688.0\nNaN\nNaN\nNaN\n\n\n16099\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nETH\nEthiopia\nSub-Saharan Africa\nAfrica\n...\n1.0\n11.0\n2.0\nNaN\n99000.0\nNaN\n99000.0\nNaN\nNaN\nNaN\n\n\n16184\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nMMR\nMyanmar\nSouth-eastern Asia\nAsia\n...\n3.0\n28.0\n3784.0\n4824.0\n282790.0\nNaN\n287614.0\nNaN\nNaN\nNaN\n\n\n16185\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nTHA\nThailand\nSouth-eastern Asia\nAsia\n...\n3.0\n28.0\n44.0\n37.0\n2313.0\nNaN\n2350.0\nNaN\nNaN\nNaN\n\n\n16196\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nTJK\nTajikistan\nCentral Asia\nAsia\n...\n4.0\n13.0\n1.0\nNaN\n145.0\nNaN\n145.0\nNaN\nNaN\nNaN\n\n\n\n\n1356 rows × 29 columns\n\n\n\n\nfig = px.scatter_geo(\n    map_df,\n    lat='Latitude',\n    lon='Longitude',\n    color='Disaster Subtype',\n    size='Total Deaths',  \n    hover_name='Country',\n    title='Global Disasters Map',\n    size_max=30,\n)\n\nfig.update_layout(\n    geo=dict(\n        showland=True,\n        showcountries=True\n    )\n)\n\nfig.show()"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#analysis-of-map-visualization",
    "href": "posts/Environmental Machine Learning Project/index.html#analysis-of-map-visualization",
    "title": "Environmental Data Project",
    "section": "Analysis of Map Visualization",
    "text": "Analysis of Map Visualization\nHere, we can see that Haiti experienced a Ground Movement disaster that resulted in a huge amount of deaths. We also see that Indonesia has deathly tsunamis. China, Kazakhstan, and Russia face a lot of floods that have caused a large loss of lives."
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#responding-to-questions-from-research-professor-prior-week",
    "href": "posts/Environmental Machine Learning Project/index.html#responding-to-questions-from-research-professor-prior-week",
    "title": "Environmental Data Project",
    "section": "Responding to questions from research professor prior week",
    "text": "Responding to questions from research professor prior week\n\n“This is likely due to their large size, which means that there is more surface area taken into account.” -&gt; Would it be possible to apply some normalization techniques to account for differences in country size? -&gt; answer: Great idea! We could try to find another data source that contains the country size and use data techniques to merge it together. Once we’ve prepared the data, we can perform normalization techniques by dividing the number of natural disasters with the corresponding country’s size. We can try doing this during week 5 when we incorporate SQL.\nWould you consider numbering the research questions with bullet points to make them easier to reference? -&gt; Yes, I’ll go back and adjust them! This is a great piece of advice\nClarifying question “dataset spans from 2000 to 2025—is that right?” -&gt; answer: Yes, this dataset spans 25 years starting from 2000. Even though there exists data before 2000, according to the data source, “Pre-2000 data is particularly subject to reporting biases.”\nRegarding visualizations and figures: Could you ensure consistency in how parameters are represented? For example, if size represents occurrence or death, it would be helpful to maintain that convention across all figures. -&gt; answer: Yes, this is a helpful piece of advice but the reason for the inconsistency in how parameters are represented is due to how these visualizations were more so for exploratory purposes to better understand the data. I’ll keep this advice in mind and ensure consistency in how parameters are represented for the final report."
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#air-pollution-dataset-using-api",
    "href": "posts/Environmental Machine Learning Project/index.html#air-pollution-dataset-using-api",
    "title": "Environmental Data Project",
    "section": "Air Pollution Dataset Using API",
    "text": "Air Pollution Dataset Using API\nOur data source is called Open Weather Map. I made an account with them and verified my email address to obtain the API key. According to the website, “the Air Pollution API provides current, forecast and historical air pollution data for any coordinates on the globe. Besides basic Air Quality Index, the API returns data about polluting gases, such as Carbon monoxide (CO), Nitrogen monoxide (NO), Nitrogen dioxide (NO2), Ozone (O3), Sulphur dioxide (SO2), Ammonia (NH3), and particulates (PM2.5 and PM10). Air pollution forecast is available for 4 days with hourly granularity. Historical data is accessible from 27th November 2020.”\n\n\n\n\nimport requests\n\nAPI_KEY = \"dc622205c25e4f765124ba4c03f370ba\"\nLAT = 35.6764\nLON = 139.6500\n\nurl = f\"http://api.openweathermap.org/data/2.5/air_pollution\"\nparams = {\n    \"lat\": LAT,\n    \"lon\": LON,\n    \"appid\": API_KEY\n}\n\nresponse = requests.get(url, params=params)\ndata = response.json()\n\nprint(\"Air Quality Index (AQI):\", data['list'][0]['main']['aqi'])\nprint(\"Components (μg/m³):\", data['list'][0]['components'])\n\nAir Quality Index (AQI): 2\nComponents (μg/m³): {'co': 171.31, 'no': 1.28, 'no2': 17.65, 'o3': 82.99, 'so2': 7.58, 'pm2_5': 4.91, 'pm10': 7.89, 'nh3': 0.52}"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#air-quality-history",
    "href": "posts/Environmental Machine Learning Project/index.html#air-quality-history",
    "title": "Environmental Data Project",
    "section": "Air Quality History",
    "text": "Air Quality History\nThe above code is testing the usage of the API. I looked up the coordinates of Tokyo and plugged that in to obtain the Air Quality Index. I received a value of 2. Now let’s trying using the API to obtain the Air Quality History.\n\nimport requests\nimport pandas as pd\nfrom datetime import datetime\n\nAPI_KEY = \"dc622205c25e4f765124ba4c03f370ba\"\nLAT = 35.6764\nLON = 139.6500\n\nstart = int(datetime(2025, 1, 1).timestamp())\nend = int(datetime(2025, 1, 6).timestamp())  \n\nurl = \"http://api.openweathermap.org/data/2.5/air_pollution/history\"\nparams = {\n    \"lat\": LAT,\n    \"lon\": LON,\n    \"start\": start,\n    \"end\": end,\n    \"appid\": API_KEY\n}\n\nresponse = requests.get(url, params=params)\ndata = response.json()\n\nrecords = []\nfor entry in data.get(\"list\", []):\n    ts = datetime.fromtimestamp(entry[\"dt\"])\n    aqi = entry[\"main\"][\"aqi\"]\n    components = entry[\"components\"]\n    components[\"timestamp\"] = ts\n    components[\"aqi\"] = aqi\n    records.append(components)\n\ndf = pd.DataFrame(records)\ndf.set_index(\"timestamp\", inplace=True)\n\nprint(df)\n\n                         co      no     no2     o3    so2  pm2_5   pm10   nh3  \\\ntimestamp                                                                       \n2025-01-01 00:00:00  333.79    0.00   26.73  57.22  19.07   0.86   2.03  1.03   \n2025-01-01 01:00:00  323.77    0.00   23.65  59.37  16.45   0.72   1.90  0.95   \n2025-01-01 02:00:00  317.10    0.00   22.62  60.80  15.74   0.65   1.91  0.90   \n2025-01-01 03:00:00  317.10    0.00   23.31  61.51  16.21   0.67   2.04  0.89   \n2025-01-01 04:00:00  323.77    0.00   24.68  60.80  17.40   0.72   2.18  0.93   \n...                     ...     ...     ...    ...    ...    ...    ...   ...   \n2025-01-05 20:00:00  834.47  236.03  126.12   0.00  72.48  22.26  31.77  3.96   \n2025-01-05 21:00:00  741.00  189.54  116.53   0.00  58.65  20.81  28.91  3.64   \n2025-01-05 22:00:00  554.08   98.35   98.71   0.00  47.21  16.70  22.60  2.94   \n2025-01-05 23:00:00  500.68   75.10   89.11   0.00  40.53  16.16  21.01  2.28   \n2025-01-06 00:00:00  480.65   64.37   84.31   0.00  31.47  16.41  20.80  1.63   \n\n                     aqi  \ntimestamp                 \n2025-01-01 00:00:00    1  \n2025-01-01 01:00:00    1  \n2025-01-01 02:00:00    2  \n2025-01-01 03:00:00    2  \n2025-01-01 04:00:00    2  \n...                  ...  \n2025-01-05 20:00:00    3  \n2025-01-05 21:00:00    3  \n2025-01-05 22:00:00    3  \n2025-01-05 23:00:00    3  \n2025-01-06 00:00:00    3  \n\n[121 rows x 9 columns]\n\n\nNow that we have our history of the air quality over the past five days at the start of 2025, we can try to categorize it based on https://www.iaqdetectors.com/blogs/what-is-air-quality-index-uba-standardhttps://www.iaqdetectors.com/blogs/what-is-air-quality-index-uba-standard, which says: Level 1: Excellent Air Quality. AQI Range: 1 (Green) Level 2: Good Air Quality. AQI Range: 2 (Green) Level 3: Moderate Air Quality. AQI Range: 3 (Yellow) Level 4: Poor Air Quality. AQI Range: 4 (Orange) Level 5: Very Poor Air Quality. AQI Range: 5 (Red or Purple)"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#categorizing-air-quality",
    "href": "posts/Environmental Machine Learning Project/index.html#categorizing-air-quality",
    "title": "Environmental Data Project",
    "section": "Categorizing Air Quality",
    "text": "Categorizing Air Quality\n\ndef categorize_aqi(aqi):\n    if aqi == 1:\n        return \"Excellent\"\n    elif aqi == 2:\n        return \"Good\"\n    elif aqi == 3:\n        return \"Moderate\"\n    elif aqi == 4:\n        return \"Poor\"\n    else:\n        return \"Very Poor\"\n\ndf[\"risk_level\"] = df[\"aqi\"].apply(categorize_aqi)\n\nprint(df)\n\n                         co      no     no2     o3    so2  pm2_5   pm10   nh3  \\\ntimestamp                                                                       \n2025-01-01 00:00:00  333.79    0.00   26.73  57.22  19.07   0.86   2.03  1.03   \n2025-01-01 01:00:00  323.77    0.00   23.65  59.37  16.45   0.72   1.90  0.95   \n2025-01-01 02:00:00  317.10    0.00   22.62  60.80  15.74   0.65   1.91  0.90   \n2025-01-01 03:00:00  317.10    0.00   23.31  61.51  16.21   0.67   2.04  0.89   \n2025-01-01 04:00:00  323.77    0.00   24.68  60.80  17.40   0.72   2.18  0.93   \n...                     ...     ...     ...    ...    ...    ...    ...   ...   \n2025-01-05 20:00:00  834.47  236.03  126.12   0.00  72.48  22.26  31.77  3.96   \n2025-01-05 21:00:00  741.00  189.54  116.53   0.00  58.65  20.81  28.91  3.64   \n2025-01-05 22:00:00  554.08   98.35   98.71   0.00  47.21  16.70  22.60  2.94   \n2025-01-05 23:00:00  500.68   75.10   89.11   0.00  40.53  16.16  21.01  2.28   \n2025-01-06 00:00:00  480.65   64.37   84.31   0.00  31.47  16.41  20.80  1.63   \n\n                     aqi risk_level  \ntimestamp                            \n2025-01-01 00:00:00    1  Excellent  \n2025-01-01 01:00:00    1  Excellent  \n2025-01-01 02:00:00    2       Good  \n2025-01-01 03:00:00    2       Good  \n2025-01-01 04:00:00    2       Good  \n...                  ...        ...  \n2025-01-05 20:00:00    3   Moderate  \n2025-01-05 21:00:00    3   Moderate  \n2025-01-05 22:00:00    3   Moderate  \n2025-01-05 23:00:00    3   Moderate  \n2025-01-06 00:00:00    3   Moderate  \n\n[121 rows x 10 columns]"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#line-graph-on-air-quality",
    "href": "posts/Environmental Machine Learning Project/index.html#line-graph-on-air-quality",
    "title": "Environmental Data Project",
    "section": "Line graph on Air Quality",
    "text": "Line graph on Air Quality\nAfter, we can visualize the data over the 5 day period!\n\ndef AQI_Plot(df, start, end, location):\n    fig = px.line(df, x=df.index, y=\"aqi\", title=f\"Air Quality Index (AQI) in {location} from {start} to {end}\",\n              labels={\"AQI\": \"AQI\", \"timestamp\": \"Date\"})\n\n    fig.update_traces(line=dict(color='blue'))\n    fig.update_layout(yaxis_title=\"AQI\", xaxis_title=\"Date\")\n\n    fig.show()\nAQI_Plot(df, \"2025-01-01\" ,\"2025-01-06\", \"Tokyo\" )\n\n\n\n\nHowever, if we wanted to incorporate the risk levels onto the visualization, we can add some color identification by specifying the color discrete map. The downside is that it is no longer continuous and a little harder to understand since the levels change so dramatically.\n\nimport plotly.express as px\n\ndef AQI_Color_Plot(df, start, end, location):\n\n    fig = px.scatter(df, x=df.index, y=\"aqi\", color=\"risk_level\",\n                    title=f\"Air Quality Index (AQI) in {location} from {start} to {end}\",\n                    labels={\"aqi\": \"AQI\", \"timestamp\": \"Date\"},\n                    color_discrete_map={\n                        \"Excellent\": \"green\",\n                        \"Good\": \"limegreen\",\n                        \"Moderate\": \"orange\",\n                        \"Poor\": \"orangered\",\n                        \"Very Poor\": \"red\"\n                    })\n\n    fig.update_traces(mode=\"lines+markers\")\n    fig.update_layout(yaxis_title=\"AQI\", xaxis_title=\"Date\")\n\n    fig.show()\nAQI_Color_Plot(df, \"2025-01-01\" ,\"2025-01-06\", \"Tokyo\" )\n\n\n\n\nNow let’s wrap everything into a function so that the parameters can be easily changed based on user input.\n\ndef create_df(lat, lon, start, end, location):\n    API_KEY = \"dc622205c25e4f765124ba4c03f370ba\"\n    LAT = lat\n    LON = lon\n\n    start = int(datetime.strptime(start, \"%Y-%m-%d\").timestamp())\n    end = int(datetime.strptime(end, \"%Y-%m-%d\").timestamp())\n\n    url = \"http://api.openweathermap.org/data/2.5/air_pollution/history\"\n    params = {\n        \"lat\": LAT,\n        \"lon\": LON,\n        \"start\": start,\n        \"end\": end,\n        \"appid\": API_KEY\n    }\n\n    response = requests.get(url, params=params)\n    data = response.json()\n\n    records = []\n    for entry in data.get(\"list\", []):\n        ts = datetime.fromtimestamp(entry[\"dt\"])\n        aqi = entry[\"main\"][\"aqi\"]\n        components = entry[\"components\"]\n        components[\"timestamp\"] = ts\n        components[\"aqi\"] = aqi\n        records.append(components)\n\n        df = pd.DataFrame(records)\n        df.set_index(\"timestamp\", inplace=True)\n        \n        def categorize_aqi(aqi):\n            if aqi == 1:\n                return \"Excellent\"\n            elif aqi == 2:\n                return \"Good\"\n            elif aqi == 3:\n                return \"Moderate\"\n            elif aqi == 4:\n                return \"Poor\"\n            else:\n                return \"Very Poor\"\n\n    df[\"risk_level\"] = df[\"aqi\"].apply(categorize_aqi)\n\n    print(df)\n    AQI_Color_Plot(df, start, end, location )"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#example-usage-of-our-function-for-the-specific-location-los-angeles",
    "href": "posts/Environmental Machine Learning Project/index.html#example-usage-of-our-function-for-the-specific-location-los-angeles",
    "title": "Environmental Data Project",
    "section": "Example usage of our function for the specific location Los Angeles",
    "text": "Example usage of our function for the specific location Los Angeles\nHere we are using the coordinates of Los Angeles and observing the air quality between Jan. 5 and Jan. 10, 2025, which was during the wildfires in the Palisades and Eaton Canyon.\n\nlat = 34.0549\nlon = 118.2426\nstart_date = \"2025-01-05\" \nend_date = \"2025-01-10\" \nlocation = \"Los Angeles\"\n\ndf = create_df(lat, lon, start_date, end_date, location)\nprint(df)\n\n                          co     no    no2     o3    so2   pm2_5    pm10  \\\ntimestamp                                                                  \n2025-01-05 00:00:00  1735.69  29.95  58.95   0.00  15.74  173.36  225.51   \n2025-01-05 01:00:00  1642.23  29.50  61.01   0.00  14.78  173.32  217.93   \n2025-01-05 02:00:00  1562.12  29.50  63.75   0.00  14.90  175.63  215.06   \n2025-01-05 03:00:00  1482.01  28.61  67.17   0.00  15.50  178.79  215.36   \n2025-01-05 04:00:00  1415.25  25.70  70.60   0.00  16.45  187.26  221.11   \n...                      ...    ...    ...    ...    ...     ...     ...   \n2025-01-09 20:00:00   614.17   0.02  43.87  33.97  42.92   38.82   61.52   \n2025-01-09 21:00:00   620.84   0.02  44.55  32.54  44.82   38.22   61.39   \n2025-01-09 22:00:00   647.54   0.04  49.35  28.25  51.98   39.03   61.56   \n2025-01-09 23:00:00   754.36   0.14  61.69  17.70  62.94   47.53   71.75   \n2025-01-10 00:00:00   834.47   0.31  71.29  11.00  66.76   54.43   79.63   \n\n                      nh3  aqi risk_level  \ntimestamp                                  \n2025-01-05 00:00:00  3.20    5  Very Poor  \n2025-01-05 01:00:00  2.03    5  Very Poor  \n2025-01-05 02:00:00  1.33    5  Very Poor  \n2025-01-05 03:00:00  0.81    5  Very Poor  \n2025-01-05 04:00:00  0.34    5  Very Poor  \n...                   ...  ...        ...  \n2025-01-09 20:00:00  6.46    3   Moderate  \n2025-01-09 21:00:00  7.16    3   Moderate  \n2025-01-09 22:00:00  7.41    3   Moderate  \n2025-01-09 23:00:00  8.61    3   Moderate  \n2025-01-10 00:00:00  9.88    4       Poor  \n\n[121 rows x 10 columns]\n\n\n\n\n\nNone"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#normalization-techniques-to-account-for-differences-in-country-size",
    "href": "posts/Environmental Machine Learning Project/index.html#normalization-techniques-to-account-for-differences-in-country-size",
    "title": "Environmental Data Project",
    "section": "Normalization techniques to account for differences in country size",
    "text": "Normalization techniques to account for differences in country size\n“This is likely due to their large size, which means that there is more surface area taken into account.” -&gt; Would it be possible to apply some normalization techniques to account for differences in country size? -&gt; answer: Great idea! We could try to find another data source that contains the country size and use data techniques to merge it together. Once we’ve prepared the data, we can perform normalization techniques by dividing the number of natural disasters with the corresponding country’s size."
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#obtain-world-population-dataset",
    "href": "posts/Environmental Machine Learning Project/index.html#obtain-world-population-dataset",
    "title": "Environmental Data Project",
    "section": "Obtain World Population Dataset",
    "text": "Obtain World Population Dataset\nFirst thing, we want a dataset on the population of each country. By doing a Google Search, I was able to find one on Kaggle.\n\n\n\n\ndf_pop = pd.read_csv('world_population.csv')\ndf_pop\n\n\n\n\n\n\n\n\nRank\nCCA3\nCountry/Territory\nCapital\nContinent\n2022 Population\n2020 Population\n2015 Population\n2010 Population\n2000 Population\n1990 Population\n1980 Population\n1970 Population\nArea (km²)\nDensity (per km²)\nGrowth Rate\nWorld Population Percentage\n\n\n\n\n0\n36\nAFG\nAfghanistan\nKabul\nAsia\n41128771\n38972230\n33753499\n28189672\n19542982\n10694796\n12486631\n10752971\n652230\n63.0587\n1.0257\n0.52\n\n\n1\n138\nALB\nAlbania\nTirana\nEurope\n2842321\n2866849\n2882481\n2913399\n3182021\n3295066\n2941651\n2324731\n28748\n98.8702\n0.9957\n0.04\n\n\n2\n34\nDZA\nAlgeria\nAlgiers\nAfrica\n44903225\n43451666\n39543154\n35856344\n30774621\n25518074\n18739378\n13795915\n2381741\n18.8531\n1.0164\n0.56\n\n\n3\n213\nASM\nAmerican Samoa\nPago Pago\nOceania\n44273\n46189\n51368\n54849\n58230\n47818\n32886\n27075\n199\n222.4774\n0.9831\n0.00\n\n\n4\n203\nAND\nAndorra\nAndorra la Vella\nEurope\n79824\n77700\n71746\n71519\n66097\n53569\n35611\n19860\n468\n170.5641\n1.0100\n0.00\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n229\n226\nWLF\nWallis and Futuna\nMata-Utu\nOceania\n11572\n11655\n12182\n13142\n14723\n13454\n11315\n9377\n142\n81.4930\n0.9953\n0.00\n\n\n230\n172\nESH\nWestern Sahara\nEl Aaiún\nAfrica\n575986\n556048\n491824\n413296\n270375\n178529\n116775\n76371\n266000\n2.1654\n1.0184\n0.01\n\n\n231\n46\nYEM\nYemen\nSanaa\nAsia\n33696614\n32284046\n28516545\n24743946\n18628700\n13375121\n9204938\n6843607\n527968\n63.8232\n1.0217\n0.42\n\n\n232\n63\nZMB\nZambia\nLusaka\nAfrica\n20017675\n18927715\n16248230\n13792086\n9891136\n7686401\n5720438\n4281671\n752612\n26.5976\n1.0280\n0.25\n\n\n233\n74\nZWE\nZimbabwe\nHarare\nAfrica\n16320537\n15669666\n14154937\n12839771\n11834676\n10113893\n7049926\n5202918\n390757\n41.7665\n1.0204\n0.20\n\n\n\n\n234 rows × 17 columns"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#create-and-use-sql-databases-for-data-manipulation",
    "href": "posts/Environmental Machine Learning Project/index.html#create-and-use-sql-databases-for-data-manipulation",
    "title": "Environmental Data Project",
    "section": "Create and Use SQL Databases for Data Manipulation",
    "text": "Create and Use SQL Databases for Data Manipulation\nSo now, we have two seperate databases. One on EMDAT data and the other one containing information of different countries. Because our goal is to apply some normalization techniques to account for differences in country size, we want to use SQL to merge the two databases. Our first step is to import SQL and then start a connection. With this connection, we can convert the two df’s into sql.\n\nimport sqlite3\nconn = sqlite3.connect(\"pop.sqlite\")\n\n\n\nwith sqlite3.connect(\"pop.sqlite\") as conn:\n    df_pop.to_sql(\"pop\", conn, if_exists=\"replace\", index=False)\n    map_df.to_sql(\"emdat\", conn, if_exists=\"replace\", index=False)\n\n\nwith sqlite3.connect(\"pop.sqlite\") as conn:\n    merged_df = pd.read_sql_query(\"\"\"\n        SELECT \n            e.*,\n            p.\"Area (km²)\"\n        FROM \n            emdat e\n        JOIN \n            pop p\n        ON \n            LOWER(e.Country) = LOWER(p.\"Country/Territory\")\n    \"\"\", conn)\n\nmerged_df\n\n\n\n\n\n\n\n\nHistoric\nClassification Key\nDisaster Group\nDisaster Subgroup\nDisaster Type\nDisaster Subtype\nISO\nCountry\nSubregion\nRegion\n...\nEnd Day\nTotal Deaths\nNo. Injured\nNo. Affected\nNo. Homeless\nTotal Affected\nTotal Damage ('000 US$)\nTotal Damage, Adjusted ('000 US$)\nCPI\nArea (km²)\n\n\n\n\n0\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nCHN\nChina\nEastern Asia\nAsia\n...\n14.0\n7.0\n2528.0\n1760000.0\n92479.0\n1855007.0\n73500.0\n130056.0\n56.514291\n9706961\n\n\n1\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nCHN\nChina\nEastern Asia\nAsia\n...\n26.0\n1.0\n2.0\n10300.0\nNaN\n10302.0\n483.0\n855.0\n56.514291\n9706961\n\n\n2\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nCOL\nColombia\nLatin America and the Caribbean\nAmericas\n...\n8.0\n2.0\nNaN\n430.0\nNaN\n430.0\nNaN\nNaN\n56.514291\n1141748\n\n\n3\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nIDN\nIndonesia\nSouth-eastern Asia\nAsia\n...\n4.0\n45.0\n270.0\nNaN\n52500.0\n52770.0\n30000.0\n53084.0\n56.514291\n1904569\n\n\n4\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nIDN\nIndonesia\nSouth-eastern Asia\nAsia\n...\n4.0\n103.0\n2714.0\n200000.0\n2000.0\n204714.0\n41000.0\n72548.0\n56.514291\n1904569\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1127\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nCHN\nChina\nEastern Asia\nAsia\n...\n7.0\n126.0\n188.0\n46500.0\nNaN\n46688.0\nNaN\nNaN\nNaN\n9706961\n\n\n1128\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nETH\nEthiopia\nSub-Saharan Africa\nAfrica\n...\n11.0\n2.0\nNaN\n99000.0\nNaN\n99000.0\nNaN\nNaN\nNaN\n1104300\n\n\n1129\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nMMR\nMyanmar\nSouth-eastern Asia\nAsia\n...\n28.0\n3784.0\n4824.0\n282790.0\nNaN\n287614.0\nNaN\nNaN\nNaN\n676578\n\n\n1130\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nTHA\nThailand\nSouth-eastern Asia\nAsia\n...\n28.0\n44.0\n37.0\n2313.0\nNaN\n2350.0\nNaN\nNaN\nNaN\n513120\n\n\n1131\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nTJK\nTajikistan\nCentral Asia\nAsia\n...\n13.0\n1.0\nNaN\n145.0\nNaN\n145.0\nNaN\nNaN\nNaN\n143100\n\n\n\n\n1132 rows × 30 columns"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#visualization",
    "href": "posts/Environmental Machine Learning Project/index.html#visualization",
    "title": "Environmental Data Project",
    "section": "Visualization",
    "text": "Visualization\nNow we can create the new visualization, but this time, the deaths are normalized by the country size.\n\ndisaster_counts = merged_df.groupby('Country').size().reset_index(name='disaster_count')\n\nmerged_df = merged_df.merge(disaster_counts, on='Country', how='left')\n\nmerged_df['disasters_normalized_by_size'] = round(\n    merged_df['disaster_count'] / merged_df['Area (km²)'] * 100000, 2\n)\n\n\n\nmerged_df\n\n\n\n\n\n\n\n\nHistoric\nClassification Key\nDisaster Group\nDisaster Subgroup\nDisaster Type\nDisaster Subtype\nISO\nCountry\nSubregion\nRegion\n...\nNo. Injured\nNo. Affected\nNo. Homeless\nTotal Affected\nTotal Damage ('000 US$)\nTotal Damage, Adjusted ('000 US$)\nCPI\nArea (km²)\ndisaster_count\ndisasters_normalized_by_size\n\n\n\n\n0\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nCHN\nChina\nEastern Asia\nAsia\n...\n2528.0\n1760000.0\n92479.0\n1855007.0\n73500.0\n130056.0\n56.514291\n9706961\n114\n1.17\n\n\n1\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nCHN\nChina\nEastern Asia\nAsia\n...\n2.0\n10300.0\nNaN\n10302.0\n483.0\n855.0\n56.514291\n9706961\n114\n1.17\n\n\n2\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nCOL\nColombia\nLatin America and the Caribbean\nAmericas\n...\nNaN\n430.0\nNaN\n430.0\nNaN\nNaN\n56.514291\n1141748\n18\n1.58\n\n\n3\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nIDN\nIndonesia\nSouth-eastern Asia\nAsia\n...\n270.0\nNaN\n52500.0\n52770.0\n30000.0\n53084.0\n56.514291\n1904569\n101\n5.30\n\n\n4\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nIDN\nIndonesia\nSouth-eastern Asia\nAsia\n...\n2714.0\n200000.0\n2000.0\n204714.0\n41000.0\n72548.0\n56.514291\n1904569\n101\n5.30\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1127\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nCHN\nChina\nEastern Asia\nAsia\n...\n188.0\n46500.0\nNaN\n46688.0\nNaN\nNaN\nNaN\n9706961\n114\n1.17\n\n\n1128\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nETH\nEthiopia\nSub-Saharan Africa\nAfrica\n...\nNaN\n99000.0\nNaN\n99000.0\nNaN\nNaN\nNaN\n1104300\n10\n0.91\n\n\n1129\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nMMR\nMyanmar\nSouth-eastern Asia\nAsia\n...\n4824.0\n282790.0\nNaN\n287614.0\nNaN\nNaN\nNaN\n676578\n13\n1.92\n\n\n1130\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nTHA\nThailand\nSouth-eastern Asia\nAsia\n...\n37.0\n2313.0\nNaN\n2350.0\nNaN\nNaN\nNaN\n513120\n21\n4.09\n\n\n1131\nNo\nnat-geo-ear-gro\nNatural\nGeophysical\nEarthquake\nGround movement\nTJK\nTajikistan\nCentral Asia\nAsia\n...\nNaN\n145.0\nNaN\n145.0\nNaN\nNaN\nNaN\n143100\n9\n6.29\n\n\n\n\n1132 rows × 32 columns\n\n\n\n\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default=\"iframe\"\n\nfig = px.scatter(\n    merged_df.query('disaster_count'),\n    x=\"Country\",\n    y=\"disaster_count\",\n    size=\"disasters_normalized_by_size\",\n    color=\"Country\",\n    hover_name=\"Country\",\n    log_y=True, \n    size_max=100,\n    title=\"Number of Disaster Types by Country\"\n)\n\nfig.show()"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#lets-revist-our-first-research-question",
    "href": "posts/Environmental Machine Learning Project/index.html#lets-revist-our-first-research-question",
    "title": "Environmental Data Project",
    "section": "Let’s revist our first research question",
    "text": "Let’s revist our first research question\nNow that we normalized the disaster count by size of the country, we can take a second look at the research question. 1. “Which countries have experienced the highest number of natural disasters?” - We’ll need to investigate variables on countries, when it occured, and type of disaster"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#analysis-of-first-research-question-1",
    "href": "posts/Environmental Machine Learning Project/index.html#analysis-of-first-research-question-1",
    "title": "Environmental Data Project",
    "section": "Analysis of first research question",
    "text": "Analysis of first research question\nFrom this visualization, we can see that Rwanda, El Savador, and the Philippines have experienced the highest number of natural disasters per 100,000 squared km. Comparing this with the original visualization, we can see that there are differences in the coutnries with the highest numebr of natural diasters where we previously found India, China, and the USA noteworthy due to their large size."
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#download-machine-learning-imports",
    "href": "posts/Environmental Machine Learning Project/index.html#download-machine-learning-imports",
    "title": "Environmental Data Project",
    "section": "Download machine learning imports",
    "text": "Download machine learning imports\n\nimport numpy as np\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nimport keras\nimport tensorflow as tf\nkeras.__version__\n\n'3.10.0'"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#choose-dataset-for-machine-learning",
    "href": "posts/Environmental Machine Learning Project/index.html#choose-dataset-for-machine-learning",
    "title": "Environmental Data Project",
    "section": "Choose dataset for machine learning",
    "text": "Choose dataset for machine learning\nOur dataset is multi-spectral values of pixels in 3x3 neighbourhoods in a satellite image, and the classification associated with the central pixel in each neighbourhood. We are using machine learning and 36 data variables to predict the seven types of classes which are:\n1 red soil 2 cotton crop 3 grey soil 4 damp grey soil 5 soil with vegetation stubble 6 mixture class (all types present) 7 very damp grey soil\n\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/satimage/sat.trn\"\ncol_names = [f\"feature_{i}\" for i in range(36)] + [\"label\"]\ndf = pd.read_csv(url, sep='\\\\s+', header=None, names=col_names)\n\n# Drop na\ndf = df.dropna()\n\nX = df.drop(\"label\", axis=1).astype(np.float32).values #predictor data is everything except label\ny = df[\"label\"].values #target data is the label\n\nle = LabelEncoder()\ny = le.fit_transform(y)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#investigate-data",
    "href": "posts/Environmental Machine Learning Project/index.html#investigate-data",
    "title": "Environmental Data Project",
    "section": "Investigate data",
    "text": "Investigate data\nLet’s look at the shape, as well as the first five rows of the predictor data and the target data.\n\nX_train.shape\n\n(3104, 36)\n\n\n\nX_train[:5] # first five rows of predictor data\n\narray([[ 79.,  95., 100.,  75.,  75.,  87.,  93.,  71.,  75.,  83.,  85.,\n         71.,  86., 100., 112.,  85.,  86., 100., 112.,  85.,  82.,  96.,\n        100.,  81.,  83., 103., 105.,  79.,  83., 103., 105.,  83.,  87.,\n        103., 105.,  83.],\n       [ 67., 112., 124.,  98.,  63., 112., 124.,  98.,  63., 108., 124.,\n        101.,  63., 111., 124.,  97.,  63., 120., 124., 101.,  63., 115.,\n        124., 101.,  64., 115., 125.,  98.,  64., 115., 125., 102.,  64.,\n        115., 125.,  98.],\n       [ 76.,  87.,  91.,  67.,  71.,  87.,  87.,  70.,  76.,  91.,  91.,\n         78.,  75.,  83.,  81.,  62.,  71.,  79.,  85.,  67.,  71.,  83.,\n         81.,  67.,  74.,  87.,  84.,  66.,  78.,  87.,  84.,  70.,  74.,\n         79.,  84.,  63.],\n       [ 82.,  96., 100.,  81.,  78.,  91.,  96.,  78.,  78.,  91.,  96.,\n         78.,  79.,  91., 101.,  75.,  79.,  95., 105.,  79.,  83.,  95.,\n         97.,  75.,  82.,  92.,  97.,  80.,  82.,  92., 101.,  83.,  85.,\n         97., 101.,  80.],\n       [ 71.,  83.,  89.,  75.,  71.,  79.,  89.,  75.,  63.,  64.,  85.,\n         75.,  74.,  83.,  88.,  70.,  74.,  83.,  88.,  74.,  74.,  83.,\n         88.,  74.,  75.,  84.,  93.,  75.,  75.,  84.,  90.,  72.,  71.,\n         81.,  93.,  75.]], dtype=float32)\n\n\n\ny_train[:5] # first five rows of target data\n\narray([2, 0, 5, 3, 5])\n\n\n\nfrom keras import layers\n\nmodel = keras.models.Sequential([\n    layers.Input((36,)), \n    layers.Dense(500, activation=\"relu\"),\n    layers.Dense(500, activation=\"relu\"),\n    layers.Dense(len(np.unique(y))) \n])\n\n\nmodel.summary()\n\nModel: \"sequential_11\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_18 (Dense)                │ (None, 500)            │        18,500 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_19 (Dense)                │ (None, 500)            │       250,500 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_20 (Dense)                │ (None, 6)              │         3,006 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n\n\n\n Total params: 272,006 (1.04 MB)\n\n\n\n Trainable params: 272,006 (1.04 MB)\n\n\n\n Non-trainable params: 0 (0.00 B)"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#train-the-data-and-make-predictions",
    "href": "posts/Environmental Machine Learning Project/index.html#train-the-data-and-make-predictions",
    "title": "Environmental Data Project",
    "section": "Train the data and make predictions",
    "text": "Train the data and make predictions\n\nmodel(X_train[:5])\n\n&lt;tf.Tensor: shape=(5, 6), dtype=float32, numpy=\narray([[-59.840546 , -28.11649  ,   9.300575 ,  13.508272 , -64.32475  ,\n        -29.1754   ],\n       [-59.374634 , -30.725103 ,   8.224603 ,  17.244871 , -71.97246  ,\n        -32.705643 ],\n       [-52.210888 , -23.572702 ,   4.798986 ,  10.781328 , -56.349655 ,\n        -24.837269 ],\n       [-57.679657 , -27.35187  ,   7.1376467,  14.23564  , -62.67731  ,\n        -27.308472 ],\n       [-54.924942 , -25.236101 ,   6.6893754,  13.306425 , -56.897594 ,\n        -25.36     ]], dtype=float32)&gt;\n\n\nWe can apply the softmax layer to transform the data into probabilities.\n\nsoftmax = keras.layers.Softmax()\nsoftmax(model(X_train[:5]))\n\n&lt;tf.Tensor: shape=(5, 6), dtype=float32, numpy=\narray([[1.37593833e-32, 8.24479558e-19, 1.46624139e-02, 9.85337496e-01,\n        1.55286098e-34, 2.85958276e-19],\n       [5.30296129e-34, 1.46842673e-21, 1.20919045e-04, 9.99879122e-01,\n        0.00000000e+00, 2.02634852e-22],\n       [4.38261151e-28, 1.19988527e-15, 2.51656072e-03, 9.97483373e-01,\n        6.98700150e-30, 3.38801003e-16],\n       [5.85091499e-32, 8.67791355e-19, 8.26079748e-04, 9.99173939e-01,\n        3.95159048e-34, 9.06279242e-19],\n       [2.32762232e-30, 1.82227161e-17, 1.33558456e-03, 9.98664379e-01,\n        3.23744263e-31, 1.60991665e-17]], dtype=float32)&gt;"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#compile-the-model-by-specifying-the-loss-function-and-optimization-algorithm",
    "href": "posts/Environmental Machine Learning Project/index.html#compile-the-model-by-specifying-the-loss-function-and-optimization-algorithm",
    "title": "Environmental Data Project",
    "section": "Compile the model, by specifying the loss function and optimization algorithm",
    "text": "Compile the model, by specifying the loss function and optimization algorithm\n\nloss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nmodel.compile(optimizer= \"adam\", loss = loss_fn, metrics=[\"accuracy\"])\n\n\nhistory = model.fit(X_train, y_train, epochs = 20,  verbose=1)\n\nEpoch 1/20\n97/97 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.4473 - loss: 16.3183\nEpoch 2/20\n97/97 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.6662 - loss: 1.1052\nEpoch 3/20\n97/97 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.6687 - loss: 1.3513\nEpoch 4/20\n97/97 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7382 - loss: 0.8283\nEpoch 5/20\n97/97 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7448 - loss: 0.8583\nEpoch 6/20\n97/97 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7361 - loss: 0.7511\nEpoch 7/20\n97/97 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7575 - loss: 0.6375\nEpoch 8/20\n97/97 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7653 - loss: 0.6094\nEpoch 9/20\n97/97 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7653 - loss: 0.5858\nEpoch 10/20\n97/97 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7846 - loss: 0.5468\nEpoch 11/20\n97/97 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7954 - loss: 0.5088\nEpoch 12/20\n97/97 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7851 - loss: 0.5337\nEpoch 13/20\n97/97 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8137 - loss: 0.4870\nEpoch 14/20\n97/97 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7994 - loss: 0.5150\nEpoch 15/20\n97/97 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7982 - loss: 0.4913\nEpoch 16/20\n97/97 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8056 - loss: 0.4910\nEpoch 17/20\n97/97 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8101 - loss: 0.4929\nEpoch 18/20\n97/97 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8350 - loss: 0.4505\nEpoch 19/20\n97/97 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8135 - loss: 0.4591\nEpoch 20/20\n97/97 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8272 - loss: 0.4332"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#plot-the-progress-of-the-training-over-time",
    "href": "posts/Environmental Machine Learning Project/index.html#plot-the-progress-of-the-training-over-time",
    "title": "Environmental Data Project",
    "section": "Plot the progress of the training over time",
    "text": "Plot the progress of the training over time\nThe training accuracy is improving over time and is hovering at around 80%.\n\nfrom matplotlib import pyplot as plt\nplt.plot(history.history[\"accuracy\"])\nplt.gca().set(xlabel=\"epoch\", ylabel=\"training accuracy\")"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#evaluate-the-model-on-our-test-data",
    "href": "posts/Environmental Machine Learning Project/index.html#evaluate-the-model-on-our-test-data",
    "title": "Environmental Data Project",
    "section": "Evaluate the model on our test data",
    "text": "Evaluate the model on our test data\nWe’re able to achieve an accuracy of around 80%.\n\nmodel.evaluate(X_test, y_test, verbose=2)\n\n42/42 - 0s - 3ms/step - accuracy: 0.8084 - loss: 0.4991\n\n\n[0.49911341071128845, 0.8084146976470947]"
  },
  {
    "objectID": "posts/Environmental Machine Learning Project/index.html#prediction-probabilities",
    "href": "posts/Environmental Machine Learning Project/index.html#prediction-probabilities",
    "title": "Environmental Data Project",
    "section": "Prediction Probabilities",
    "text": "Prediction Probabilities\n\nmodel(X_train[:5])\n\n&lt;tf.Tensor: shape=(5, 6), dtype=float32, numpy=\narray([[ -4.61132  ,  -5.4756303,   3.9168983,   2.9974535,  -5.0337152,\n          2.8182533],\n       [ 11.904403 ,  -9.574733 ,  -0.4442518,  -3.9789078,  -3.848419 ,\n        -11.430846 ],\n       [ -5.5762663,  -4.828492 ,   1.9301039,   2.1198177,  -4.007193 ,\n          5.0956087],\n       [ -5.1913986,  -5.278966 ,   3.028898 ,   2.4791439,  -4.607054 ,\n          3.698829 ],\n       [ -5.188107 ,  -4.5503697,   1.3234905,   1.383246 ,  -3.5140615,\n          2.3614984]], dtype=float32)&gt;\n\n\n\nprob_model = keras.models.Sequential([\n    model,\n    layers.Softmax()\n])\n\n\nprob_model(X_train[:5])\n\n&lt;tf.Tensor: shape=(5, 6), dtype=float32, numpy=\narray([[1.14176117e-04, 4.81072020e-05, 5.77209413e-01, 2.30156690e-01,\n        7.48396196e-05, 1.92396849e-01],\n       [9.99995470e-01, 4.69599970e-10, 4.33556215e-06, 1.26463163e-07,\n        1.44090194e-07, 7.33885314e-11],\n       [2.12075811e-05, 4.47966231e-05, 3.85892391e-02, 4.66506742e-02,\n        1.01842896e-04, 9.14592266e-01],\n       [7.61949705e-05, 6.98065705e-05, 2.83110261e-01, 1.63380593e-01,\n        1.36679591e-04, 5.53226471e-01],\n       [3.03448236e-04, 5.74183068e-04, 2.04190478e-01, 2.16763899e-01,\n        1.61850255e-03, 5.76549470e-01]], dtype=float32)&gt;\n\n\n\npredictions = prob_model.predict(X_test).argmax(axis = 1)\npredictions\n\n42/42 ━━━━━━━━━━━━━━━━━━━━ 0s 995us/step\n\n\narray([5, 0, 5, ..., 2, 0, 0])\n\n\n\n[le.classes_[predictions[i]] for i in range(10)]\n\n[7, 1, 7, 1, 3, 7, 1, 1, 1, 7]"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "mlresearch",
    "section": "",
    "text": "Environmental Data Project\n\n\n\n\n\n\n\n\n\n\n\nApr 21, 2025\n\n\nMegan Tieu\n\n\n\n\n\n\nNo matching items"
  }
]